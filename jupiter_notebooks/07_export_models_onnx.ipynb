{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dafaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt\n",
    "\n",
    "try:\n",
    "    from onnxmltools.convert import convert_xgboost, convert_lightgbm\n",
    "    xgb_lgbm_available = True\n",
    "except:\n",
    "    xgb_lgbm_available = False\n",
    "    print(\"onnxmltools nao disponivel, XGBoost e LightGBM nao serao convertidos\")\n",
    "\n",
    "print(f\"ONNX Runtime version: {rt.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '../models/'\n",
    "onnx_dir = '../models/onnx/'\n",
    "os.makedirs(onnx_dir, exist_ok=True)\n",
    "\n",
    "X_train = np.load('../data/processed/X_train.npy')\n",
    "X_test = np.load('../data/processed/X_test.npy')\n",
    "y_test = np.load('../data/processed/y_test.npy')\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8e8265",
   "metadata": {},
   "source": [
    "## Funcao para converter modelo sklearn para ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_onnx(model, model_name, n_features, output_path):\n",
    "    initial_type = [('float_input', FloatTensorType([None, n_features]))]\n",
    "    \n",
    "    try:\n",
    "        onnx_model = convert_sklearn(model, initial_types=initial_type, target_opset=12)\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"Modelo {model_name} convertido com sucesso\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter {model_name}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c20792",
   "metadata": {},
   "source": [
    "## Funcao para testar modelo ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a761885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_onnx_model(onnx_path, sklearn_model, X_sample):\n",
    "    sess = rt.InferenceSession(onnx_path)\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    label_name = sess.get_outputs()[0].name\n",
    "    \n",
    "    X_sample_float = X_sample.astype(np.float32)\n",
    "    \n",
    "    pred_onnx = sess.run([label_name], {input_name: X_sample_float})[0]\n",
    "    \n",
    "    pred_sklearn = sklearn_model.predict_proba(X_sample)[:, 1]\n",
    "    \n",
    "    if hasattr(pred_onnx[0], '__len__'):\n",
    "        pred_onnx_proba = pred_onnx[:, 1]\n",
    "    else:\n",
    "        pred_onnx_proba = pred_onnx\n",
    "    \n",
    "    diff = np.abs(pred_sklearn - pred_onnx_proba).mean()\n",
    "    \n",
    "    print(f\"Diferenca media entre predicoes: {diff:.6f}\")\n",
    "    \n",
    "    if diff < 0.001:\n",
    "        print(\"Modelo ONNX validado com sucesso\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Atencao: diferenca significativa detectada\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0f601",
   "metadata": {},
   "source": [
    "## Carregar e converter modelos individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41085332",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]\n",
    "\n",
    "print(f\"Total de modelos encontrados: {len(model_files)}\")\n",
    "print(\"Modelos:\")\n",
    "for f in model_files:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd68d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_results = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    if 'ensemble' in model_file.lower():\n",
    "        print(f\"Pulando {model_file} (ensemble nao suportado)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nProcessando: {model_file}\")\n",
    "    \n",
    "    model_path = os.path.join(models_dir, model_file)\n",
    "    \n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"  Erro ao carregar: {str(e)[:100]}\")\n",
    "        conversion_results.append({\n",
    "            'model': model_file.replace('.pkl', ''),\n",
    "            'converted': False,\n",
    "            'validated': False,\n",
    "            'path': None\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    if hasattr(model_data, 'best_estimator_'):\n",
    "        model = model_data.best_estimator_\n",
    "        print(f\"  Extraindo best_estimator_\")\n",
    "    elif hasattr(model_data, 'predict_proba'):\n",
    "        model = model_data\n",
    "    elif isinstance(model_data, dict) and 'model' in model_data:\n",
    "        model = model_data['model']\n",
    "    else:\n",
    "        print(f\"  Formato nao reconhecido, pulando\")\n",
    "        continue\n",
    "    \n",
    "    model_type = type(model).__name__\n",
    "    if 'XGB' in model_type or 'LightGBM' in model_type:\n",
    "        print(f\"  Tipo {model_type} - requer onnxmltools, pulando\")\n",
    "        conversion_results.append({\n",
    "            'model': model_file.replace('.pkl', ''),\n",
    "            'converted': False,\n",
    "            'validated': False,\n",
    "            'path': None\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    n_features = X_train.shape[1]\n",
    "    model_name = model_file.replace('.pkl', '')\n",
    "    onnx_path = os.path.join(onnx_dir, f\"{model_name}.onnx\")\n",
    "    \n",
    "    success = convert_model_to_onnx(model, model_name, n_features, onnx_path)\n",
    "    \n",
    "    if success:\n",
    "        try:\n",
    "            X_sample = X_test[:10]\n",
    "            validation = test_onnx_model(onnx_path, model, X_sample)\n",
    "        \n",
    "        conversion_results.append({\n",
    "            'model': model_name,\n",
    "            'converted': True,\n",
    "            'validated': validation,\n",
    "            'path': onnx_path\n",
    "        })\n",
    "    else:\n",
    "        conversion_results.append({\n",
    "            'model': model_name,\n",
    "            'converted': False,\n",
    "            'validated': False,\n",
    "            'path': None\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Conversao finalizada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c8476",
   "metadata": {},
   "source": [
    "## Resultados da conversao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(conversion_results)\n",
    "\n",
    "print(\"\\nResumo:\")\n",
    "print(f\"Total de modelos processados: {len(df_results)}\")\n",
    "print(f\"Convertidos com sucesso: {df_results['converted'].sum()}\")\n",
    "print(f\"Validados com sucesso: {df_results['validated'].sum()}\")\n",
    "\n",
    "print(\"\\nDetalhes:\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c241c0",
   "metadata": {},
   "source": [
    "## Salvar informacoes dos modelos ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    'n_features': X_train.shape[1],\n",
    "    'feature_names_path': '../data/processed/feature_names.txt',\n",
    "    'models': conversion_results,\n",
    "    'preprocessing': {\n",
    "        'scaler_path': '../data/processed/scaler.pkl',\n",
    "        'label_encoder_path': '../data/processed/label_encoder.pkl'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(onnx_dir, 'model_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "\n",
    "print(\"Informacoes dos modelos salvas em model_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f53fec",
   "metadata": {},
   "source": [
    "## Exemplo de uso do modelo ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_models = df_results[df_results['validated'] == True]\n",
    "\n",
    "if len(successful_models) > 0:\n",
    "    example_model_path = successful_models.iloc[0]['path']\n",
    "    print(f\"Testando modelo: {successful_models.iloc[0]['model']}\")\n",
    "    \n",
    "    sess = rt.InferenceSession(example_model_path)\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    label_name = sess.get_outputs()[0].name\n",
    "    \n",
    "    print(f\"\\nInput name: {input_name}\")\n",
    "    print(f\"Input shape: {sess.get_inputs()[0].shape}\")\n",
    "    print(f\"Output name: {label_name}\")\n",
    "    print(f\"Output shape: {sess.get_outputs()[0].shape}\")\n",
    "    \n",
    "    X_example = X_test[:5].astype(np.float32)\n",
    "    predictions = sess.run([label_name], {input_name: X_example})[0]\n",
    "    \n",
    "    print(f\"\\nPredicoes para 5 exemplos:\")\n",
    "    if hasattr(predictions[0], '__len__') and len(predictions[0]) == 2:\n",
    "        proba_class_1 = predictions[:, 1]\n",
    "        print(f\"Probabilidade de conversao: {proba_class_1}\")\n",
    "    else:\n",
    "        print(f\"Predicoes: {predictions}\")\n",
    "else:\n",
    "    print(\"Nenhum modelo validado disponivel para exemplo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88878a",
   "metadata": {},
   "source": [
    "## Criar arquivo de metadados para a API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31057d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/feature_names.txt', 'r') as f:\n",
    "    feature_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "api_metadata = {\n",
    "    'task': 'binary_classification',\n",
    "    'problem': 'Predicao de conversao MCI para Demencia em 3 anos',\n",
    "    'target_classes': ['Nao-Conversor', 'Conversor'],\n",
    "    'n_features': len(feature_names),\n",
    "    'feature_names': feature_names,\n",
    "    'models_available': [m['model'] for m in conversion_results if m['validated']],\n",
    "    'best_model': successful_models.iloc[0]['model'] if len(successful_models) > 0 else None,\n",
    "    'onnx_directory': onnx_dir\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(os.path.join(onnx_dir, 'api_metadata.json'), 'w') as f:\n",
    "    json.dump(api_metadata, f, indent=2)\n",
    "\n",
    "print(\"Metadados para API salvos em api_metadata.json\")\n",
    "print(f\"\\nModelos disponiveis para a API: {len(api_metadata['models_available'])}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
